# ä¸–ç•Œæ¨¡å‹ (World Model) - å¿«é€Ÿå¼€å§‹æŒ‡å—

## âš¡ 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹

### æ­¥éª¤ 1: æ£€æŸ¥ä¾èµ–

```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬ (éœ€è¦ 3.8+)
python --version

# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†å¿…è¦çš„åº“
python -c "import torch; import numpy; import matplotlib; from PIL import Image; print('âœ“ æ‰€æœ‰ä¾èµ–å·²å®‰è£…')"
```

å¦‚æœæç¤ºç¼ºå°‘ä¾èµ–ï¼Œè¿è¡Œï¼š
```bash
pip install torch numpy matplotlib pillow
```

### æ­¥éª¤ 2: è¿è¡Œæ¼”ç¤º

```bash
cd /Users/yefei.yf/Qoder/learn_python-1
python 29_world_model_demo.py
```

### æ­¥éª¤ 3: æŸ¥çœ‹ç»“æœ

æ¼”ç¤ºå®Œæˆåï¼Œåœ¨ `world_model_results/` ç›®å½•æŸ¥çœ‹ç”Ÿæˆçš„å›¾åƒï¼š

- ğŸ“Š **è®­ç»ƒæ›²çº¿** - è§‚å¯Ÿä¸‰ä¸ªæ¨¡å—çš„å­¦ä¹ è¿›å±•
- ğŸ–¼ï¸ **é‡æ„å¯¹æ¯”** - VAE å­¦ä¹ æ•ˆæœ
- ğŸŒˆ **æ¢¦å¢ƒåºåˆ—** - ä¸–ç•Œæ¨¡å‹çš„æƒ³è±¡
- âš–ï¸ **çœŸå® vs æ¢¦å¢ƒ** - é¢„æµ‹å‡†ç¡®åº¦

---

## ğŸ“– è¯¦ç»†ä½¿ç”¨æŒ‡å—

### åŸºç¡€ç”¨æ³•

#### 1. åˆ›å»ºå’Œè®­ç»ƒä¸–ç•Œæ¨¡å‹

```python
from world_model_core_29 import WorldModel, WorldModelConfig
from world_model_env_29 import SimpleGridWorld, DataCollector

# é…ç½®
config = WorldModelConfig()

# åˆ›å»ºç¯å¢ƒå’Œæ¨¡å‹
env = SimpleGridWorld()
world_model = WorldModel(config)

# æ”¶é›†æ•°æ®
collector = DataCollector(env, device=config.device)
observations, sequences = collector.collect_random_episodes(
    num_episodes=100,
    max_steps=50
)

# è®­ç»ƒä¸‰ä¸ªæ¨¡å—
world_model.train_vae(observations, epochs=10)
world_model.train_rnn(sequences, epochs=10)
world_model.train_controller(env, episodes=50)

# ä¿å­˜æ¨¡å‹
world_model.save("my_world_model.pt")
```

#### 2. åŠ è½½æ¨¡å‹å¹¶åšæ¢¦

```python
# åŠ è½½å·²è®­ç»ƒæ¨¡å‹
world_model = WorldModel(config)
world_model.load("my_world_model.pt")

# å‡†å¤‡åˆå§‹è§‚å¯Ÿå’ŒåŠ¨ä½œåºåˆ—
obs = env.reset()
obs_tensor = torch.FloatTensor(obs).unsqueeze(0).to(config.device)

actions = torch.FloatTensor([
    [1, 0, 0, 0],  # ä¸Š
    [0, 1, 0, 0],  # ä¸‹
    [0, 0, 1, 0],  # å·¦
    [0, 0, 0, 1],  # å³
]).to(config.device)

# åœ¨æ¢¦å¢ƒä¸­å±•å¼€
dream_data = world_model.dream(obs_tensor, actions)

# è®¿é—®æ¢¦å¢ƒæ•°æ®
dream_observations = dream_data['observations']
dream_rewards = dream_data['rewards']
```

#### 3. æµ‹è¯•æ§åˆ¶å™¨æ€§èƒ½

```python
obs = env.reset()
episode_reward = 0
hidden = None

for step in range(50):
    # è·å–æ½œåœ¨è¡¨å¾
    obs_tensor = torch.FloatTensor(obs).unsqueeze(0).to(config.device)
    z = world_model.vae.get_latent(obs_tensor)
    
    # è·å– RNN éšè—çŠ¶æ€
    if hidden is None:
        h = torch.zeros(1, config.hidden_size).to(config.device)
    else:
        h = hidden[0].squeeze(0)
    
    # é€‰æ‹©åŠ¨ä½œ
    action = world_model.controller.get_action(z, h, deterministic=True)
    
    # æ‰§è¡ŒåŠ¨ä½œ
    obs, reward, done, _ = env.step(action)
    episode_reward += reward
    
    # æ›´æ–° RNN çŠ¶æ€
    import torch.nn.functional as F
    action_onehot = F.one_hot(torch.tensor(action), 4).float()
    action_onehot = action_onehot.unsqueeze(0).unsqueeze(0).to(config.device)
    _, hidden = world_model.rnn(z.unsqueeze(1), action_onehot, hidden)
    
    if done:
        break

print(f"Episode reward: {episode_reward}")
```

---

## ğŸ›ï¸ å‚æ•°è°ƒä¼˜æŒ‡å—

### åŸºç¡€é…ç½® (å¿«é€Ÿå®éªŒ)

```python
config = WorldModelConfig(
    image_size=64,
    latent_dim=16,          # è¾ƒå°çš„æ½œåœ¨ç»´åº¦
    num_embeddings=256,     # è¾ƒå°çš„ç æœ¬
    hidden_size=128,        # è¾ƒå°çš„ RNN
    learning_rate=1e-3
)
```

è®­ç»ƒï¼š
- VAE: 5 epochs
- RNN: 5 epochs
- Controller: 20 episodes

**é€‚ç”¨**: å¿«é€Ÿæµ‹è¯•ã€æ¦‚å¿µéªŒè¯

### æ ‡å‡†é…ç½® (é»˜è®¤)

```python
config = WorldModelConfig(
    image_size=64,
    latent_dim=32,
    num_embeddings=512,
    hidden_size=256,
    learning_rate=1e-3
)
```

è®­ç»ƒï¼š
- VAE: 10 epochs
- RNN: 10 epochs
- Controller: 50 episodes

**é€‚ç”¨**: å¤§å¤šæ•°åœºæ™¯

### é«˜æ€§èƒ½é…ç½® (ç”Ÿäº§çº§)

```python
config = WorldModelConfig(
    image_size=64,
    latent_dim=64,          # æ›´å¤§çš„æ½œåœ¨ç»´åº¦
    num_embeddings=1024,    # æ›´å¤§çš„ç æœ¬
    hidden_size=512,        # æ›´å¤§çš„ RNN
    num_mixtures=10,        # æ›´å¤šæ··åˆåˆ†é‡
    learning_rate=5e-4      # æ›´å°çš„å­¦ä¹ ç‡
)
```

è®­ç»ƒï¼š
- VAE: 20+ epochs
- RNN: 20+ epochs
- Controller: 100+ episodes
- æ”¶é›† 200+ è½¨è¿¹æ•°æ®

**é€‚ç”¨**: é«˜ç²¾åº¦è¦æ±‚ã€å¤æ‚ç¯å¢ƒ

---

## ğŸ” å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜ 1: CUDA å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: `RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ 1: ä½¿ç”¨ CPU
config.device = "cpu"

# æ–¹æ¡ˆ 2: å‡å°æ‰¹æ¬¡å¤§å°
config.batch_size = 16

# æ–¹æ¡ˆ 3: å‡å°æ¨¡å‹å°ºå¯¸
config.hidden_size = 128
config.latent_dim = 16
```

### é—®é¢˜ 2: è®­ç»ƒä¸æ”¶æ•›

**ç—‡çŠ¶**: æŸå¤±ä¸ä¸‹é™æˆ–éœ‡è¡

**è§£å†³æ–¹æ¡ˆ**:
```python
# é™ä½å­¦ä¹ ç‡
config.learning_rate = 1e-4

# å¢åŠ è®­ç»ƒæ•°æ®
observations, sequences = collector.collect_random_episodes(
    num_episodes=200  # å¢åŠ åˆ° 200
)

# å»¶é•¿è®­ç»ƒæ—¶é—´
world_model.train_vae(observations, epochs=20)
```

### é—®é¢˜ 3: æ¢¦å¢ƒé¢„æµ‹ä¸å‡†ç¡®

**ç—‡çŠ¶**: `real_vs_dream.png` ä¸­å·®å¼‚å¾ˆå¤§

**åŸå› **: 
- è®­ç»ƒæ•°æ®ä¸è¶³
- æ¨¡å‹å®¹é‡ä¸å¤Ÿ
- RNN è®­ç»ƒä¸å……åˆ†

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. æ”¶é›†æ›´å¤šæ•°æ®
collector.collect_random_episodes(num_episodes=200)

# 2. å¢åŠ æ¨¡å‹å®¹é‡
config.hidden_size = 512
config.num_mixtures = 10

# 3. è®­ç»ƒæ›´é•¿æ—¶é—´
world_model.train_rnn(sequences, epochs=30)
```

### é—®é¢˜ 4: å¯¼å…¥é”™è¯¯

**ç—‡çŠ¶**: `ModuleNotFoundError` æˆ– `ImportError`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•
cd /Users/yefei.yf/Qoder/learn_python-1

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls 29_world_model_*.py

# å®‰è£…ç¼ºå¤±çš„ä¾èµ–
pip install torch numpy matplotlib pillow

# å¦‚æœæ˜¯ macOS ä¸”ä½¿ç”¨ Apple Silicon
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### åœ¨ GridWorld ç¯å¢ƒä¸Š (å‚è€ƒå€¼)

| é…ç½® | VAEæŸå¤± | RNNæŸå¤± | å¹³å‡å¥–åŠ± | è®­ç»ƒæ—¶é—´ |
|------|---------|---------|---------|---------|
| åŸºç¡€ | ~0.02 | ~3.5 | 0.3-0.4 | ~5åˆ†é’Ÿ |
| æ ‡å‡† | ~0.01 | ~2.5 | 0.4-0.6 | ~10åˆ†é’Ÿ |
| é«˜æ€§èƒ½ | ~0.005 | ~1.8 | 0.6-0.8 | ~30åˆ†é’Ÿ |

*æ³¨: åœ¨ MacBook Pro M1, CPU æ¨¡å¼ä¸‹æµ‹è¯•*

---

## ğŸ¨ å¯è§†åŒ–æŠ€å·§

### ä¿å­˜ä¸­é—´ç»“æœ

```python
# åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®šæœŸä¿å­˜
for epoch in range(50):
    if epoch % 10 == 0:
        world_model.save(f"checkpoint_epoch_{epoch}.pt")
```

### è‡ªå®šä¹‰å¯è§†åŒ–

```python
import matplotlib.pyplot as plt

# å¯è§†åŒ–æ½œåœ¨ç©ºé—´
z_list = []
for obs in observations[:100]:
    z = world_model.vae.get_latent(obs.unsqueeze(0))
    z_list.append(z.cpu().numpy())

z_array = np.concatenate(z_list, axis=0)

# ä½¿ç”¨ t-SNE é™ç»´
from sklearn.manifold import TSNE
z_2d = TSNE(n_components=2).fit_transform(z_array)

plt.scatter(z_2d[:, 0], z_2d[:, 1], alpha=0.5)
plt.title("æ½œåœ¨ç©ºé—´å¯è§†åŒ– (t-SNE)")
plt.show()
```

### ç”Ÿæˆ GIF åŠ¨ç”»

```python
from PIL import Image

# æ”¶é›†æ¢¦å¢ƒå¸§
frames = []
for obs_tensor in dream_data['observations']:
    img_array = obs_tensor.squeeze().numpy().transpose(1, 2, 0)
    img_array = (img_array * 255).astype(np.uint8)
    frames.append(Image.fromarray(img_array))

# ä¿å­˜ä¸º GIF
frames[0].save(
    'dream_animation.gif',
    save_all=True,
    append_images=frames[1:],
    duration=100,
    loop=0
)
```

---

## ğŸš€ è¿›é˜¶æŠ€å·§

### 1. åœ¨æ¢¦å¢ƒä¸­è§„åˆ’

```python
def plan_with_dream(world_model, initial_obs, num_candidates=10):
    """ä½¿ç”¨æ¢¦å¢ƒè¿›è¡Œè§„åˆ’"""
    best_reward = -float('inf')
    best_actions = None
    
    for _ in range(num_candidates):
        # ç”ŸæˆéšæœºåŠ¨ä½œåºåˆ—
        actions = torch.randint(0, 4, (10,))
        actions_onehot = F.one_hot(actions, 4).float().to(config.device)
        
        # åœ¨æ¢¦å¢ƒä¸­å±•å¼€
        dream_data = world_model.dream(initial_obs, actions_onehot)
        
        # è¯„ä¼°æ€»å¥–åŠ±
        total_reward = sum(dream_data['rewards'])
        
        if total_reward > best_reward:
            best_reward = total_reward
            best_actions = actions
    
    return best_actions[0].item()  # è¿”å›ç¬¬ä¸€ä¸ªåŠ¨ä½œ
```

### 2. ä¸»åŠ¨å­¦ä¹ 

```python
def active_learning(world_model, env, num_episodes=10):
    """æ”¶é›†æ¨¡å‹ä¸ç¡®å®šçš„æ•°æ®"""
    uncertain_states = []
    
    for _ in range(num_episodes):
        obs = env.reset()
        
        for step in range(50):
            obs_tensor = torch.FloatTensor(obs).unsqueeze(0)
            z = world_model.vae.get_latent(obs_tensor)
            
            # è¯„ä¼°ä¸ç¡®å®šæ€§ (é€šè¿‡ MDN çš„æ–¹å·®)
            # é€‰æ‹©é«˜ä¸ç¡®å®šæ€§çš„åŠ¨ä½œ
            # ...
            
            obs, _, done, _ = env.step(action)
            if done:
                break
    
    return uncertain_states
```

### 3. è¿ç§»å­¦ä¹ 

```python
# åœ¨ç¯å¢ƒ A ä¸Šè®­ç»ƒ
env_a = SimpleGridWorld(grid_size=8)
world_model.train_vae(observations_a, epochs=10)
world_model.train_rnn(sequences_a, epochs=10)

# è¿ç§»åˆ°ç¯å¢ƒ B
env_b = SimpleGridWorld(grid_size=10)  # æ›´å¤§çš„ç½‘æ ¼

# å†»ç»“ VAEï¼Œåªè®­ç»ƒ RNN å’Œ Controller
for param in world_model.vae.parameters():
    param.requires_grad = False

world_model.train_controller(env_b, episodes=30)
```

---

## ğŸ“š ä¸‹ä¸€æ­¥å­¦ä¹ 

### æ¨èé˜…è¯»é¡ºåº

1. âœ… **è¿è¡Œæ¼”ç¤º** - `python 29_world_model_demo.py`
2. ğŸ“– **é˜…è¯» README** - [`29_README_WorldModel.md`](29_README_WorldModel.md)
3. ğŸ” **ç ”ç©¶æ ¸å¿ƒä»£ç ** - [`29_world_model_core.py`](29_world_model_core.py)
4. ğŸ¨ **è‡ªå®šä¹‰ç¯å¢ƒ** - ä¿®æ”¹ `SimpleGridWorld`
5. ğŸš€ **è°ƒä¼˜å‚æ•°** - ä½¿ç”¨é«˜æ€§èƒ½é…ç½®
6. ğŸ“„ **é˜…è¯»è®ºæ–‡** - [World Models](https://arxiv.org/abs/1803.10122)

### æ‰©å±•é¡¹ç›®

- ğŸ® å®ç° CarRacing ç¯å¢ƒçš„å®Œæ•´ç‰ˆ
- ğŸ¤– é›†æˆçœŸå®æœºå™¨äºº
- ğŸ§ª å¯¹æ¯”ä¸åŒçš„ä¸–ç•Œæ¨¡å‹æ¶æ„ (Dreamer, MuZero)
- ğŸ“Š ç ”ç©¶è¡¨å¾å­¦ä¹ çš„è´¨é‡
- ğŸ¯ å®ç°åŸºäºæ¢¦å¢ƒçš„æ¨¡å‹é¢„æµ‹æ§åˆ¶ (MPC)

---

## ğŸ’¬ è·å–å¸®åŠ©

### é‡åˆ°é—®é¢˜ï¼Ÿ

1. æ£€æŸ¥ [å¸¸è§é—®é¢˜æ’æŸ¥](#-å¸¸è§é—®é¢˜æ’æŸ¥)
2. æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ [`29_README_WorldModel.md`](29_README_WorldModel.md)
3. é˜…è¯»åŸå§‹è®ºæ–‡è·å–ç†è®ºæ”¯æŒ

### æä¾›åé¦ˆ

å¦‚æœå‘ç° bug æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œæ¬¢è¿æå‡ºï¼

---

## ğŸ‰ å¿«é€Ÿå¼€å§‹æ£€æŸ¥æ¸…å•

- [ ] Python 3.8+ å·²å®‰è£…
- [ ] PyTorch å·²å®‰è£…
- [ ] è¿è¡Œæ¼”ç¤ºæˆåŠŸ
- [ ] æŸ¥çœ‹ç”Ÿæˆçš„å¯è§†åŒ–ç»“æœ
- [ ] ç†è§£ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶
- [ ] å°è¯•è°ƒæ•´å‚æ•°
- [ ] é˜…è¯»å®Œæ•´æ–‡æ¡£

å®Œæˆåï¼Œä½ å°±æŒæ¡äº†ä¸–ç•Œæ¨¡å‹çš„æ ¸å¿ƒæ¦‚å¿µï¼ğŸš€

---

**è¿”å›ä¸»æ–‡æ¡£**: [`29_README_WorldModel.md`](29_README_WorldModel.md)  
**æŸ¥çœ‹æ ¸å¿ƒä»£ç **: [`29_world_model_core.py`](29_world_model_core.py)
