"""
å¢å¼ºç‰ˆè‡ªè¿›åŒ–Agentæ¼”ç¤º
å±•ç¤ºæ›´å¤æ‚çš„å­¦ä¹ å’Œè¿›åŒ–è¡Œä¸º
"""

import sys
import os
import time
import json

# ç®€åŒ–å¯¼å…¥æ–¹å¼
exec(open('/Users/yefei.yf/Qoder/learn_python/18_self_evolving_agent.py').read())

def advanced_agent_demo():
    """é«˜çº§Agentæ¼”ç¤ºï¼Œå±•ç¤ºå¤æ‚çš„å­¦ä¹ è¡Œä¸º"""
    print("=== é«˜çº§è‡ªè¿›åŒ–Agentæ¼”ç¤º ===\n")
    
    agent = SelfEvolvingAgent("é«˜çº§å­¦ä¹ Agent")
    
    # è®¾ç½®æ›´é«˜çš„æ¢ç´¢ç‡ä»¥å±•ç¤ºå¤šæ ·åŒ–è¡Œä¸º
    agent.exploration_rate = 0.4
    
    # å¤æ‚ä»»åŠ¡åºåˆ—ï¼ŒåŒ…å«å¤±è´¥æ¡ˆä¾‹
    complex_tasks = [
        # ç¬¬ä¸€é˜¶æ®µï¼šæ¢ç´¢æœŸï¼ˆé«˜ä¸ç¡®å®šæ€§ï¼‰
        ("ç ”ç©¶é‡å­è®¡ç®—", {'uncertainty': 'high', 'complexity': 'very_high'}),
        ("åˆ†æå¤æ‚æ•°æ®", {'data': 'missing', 'format': 'unknown'}),
        ("è®¾è®¡ç¥ç»ç½‘ç»œ", {'architecture': 'uncertain', 'task': 'classification'}),
        
        # ç¬¬äºŒé˜¶æ®µï¼šå­¦ä¹ æœŸï¼ˆä¸­ç­‰ä¸ç¡®å®šæ€§ï¼‰
        ("ä¼˜åŒ–ç®—æ³•æ€§èƒ½", {'algorithm': 'genetic', 'target': 'efficiency'}),
        ("é¢„æµ‹å¸‚åœºè¶‹åŠ¿", {'data': 'historical_prices', 'timeframe': '6_months'}),
        ("è‡ªç„¶è¯­è¨€å¤„ç†", {'text': 'customer_reviews', 'task': 'sentiment'}),
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šåº”ç”¨æœŸï¼ˆä½ä¸ç¡®å®šæ€§ï¼‰  
        ("è®¡ç®—æŠ•èµ„æ”¶ç›Š", {'expression': '(1000 * 1.08 ** 5) - 1000'}),
        ("åˆ†æç”¨æˆ·è¡Œä¸º", {'data': {'clicks': 1000, 'conversions': 50}}),
        ("æœç´¢æŠ€æœ¯èµ„æ–™", {'query': 'machine learning optimization'}),
        
        # ç¬¬å››é˜¶æ®µï¼šå¤æ‚ç»„åˆä»»åŠ¡
        ("æ™ºèƒ½æ¨èç³»ç»Ÿ", {'users': 10000, 'items': 5000, 'interactions': 'sparse'}),
        ("å¤šæ¨¡æ€å­¦ä¹ ", {'vision': True, 'text': True, 'audio': False}),
        ("å¼ºåŒ–å­¦ä¹ è®­ç»ƒ", {'env': 'continuous', 'action_space': 'high_dim'}),
        
        # ç¬¬äº”é˜¶æ®µï¼šåˆ›æ–°æŒ‘æˆ˜  
        ("åˆ›å»ºæ–°ç®—æ³•", {'domain': 'optimization', 'novelty': 'required'}),
        ("è·¨é¢†åŸŸçŸ¥è¯†èåˆ", {'field1': 'biology', 'field2': 'computing'}),
        ("è§£å†³å¼€æ”¾é—®é¢˜", {'problem': 'AI_alignment', 'approach': 'unknown'})
    ]
    
    print(f"å‡†å¤‡å¤„ç† {len(complex_tasks)} ä¸ªæ¸è¿›å¼å¤æ‚ä»»åŠ¡...\n")
    
    # è®°å½•å­¦ä¹ å†ç¨‹
    learning_journey = []
    
    for i, (task, context) in enumerate(complex_tasks, 1):
        print(f"--- é˜¶æ®µ {(i-1)//3 + 1} | ä»»åŠ¡ {i}: {task} ---")
        
        # æ˜¾ç¤ºä»»åŠ¡å¤æ‚åº¦
        complexity = context.get('complexity', 'medium')
        uncertainty = context.get('uncertainty', 'medium')
        print(f"ğŸ¯ å¤æ‚åº¦: {complexity} | ä¸ç¡®å®šæ€§: {uncertainty}")
        
        # æ‰§è¡Œå‰çš„çŠ¶æ€
        pre_performance = agent.get_performance_summary()
        pre_strategies = len(agent.strategies)
        pre_concepts = len(agent.knowledge_graph.nodes)
        
        # æ‰§è¡Œä»»åŠ¡
        result = agent.process_task(task, context)
        
        # æ‰§è¡Œåçš„çŠ¶æ€
        post_performance = agent.get_performance_summary()
        post_strategies = len(agent.strategies)
        post_concepts = len(agent.knowledge_graph.nodes)
        
        # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
        print(f"ğŸ¤– é€‰æ‹©åŠ¨ä½œ: {result['action']}")
        print(f"âœ… æ‰§è¡Œç»“æœ: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
        print(f"ğŸ¯ å¥–åŠ±å€¼: {result['reward']:.2f}")
        print(f"ğŸ’¡ åæ€: {result['learning_insights']}")
        
        # æ˜¾ç¤ºå­¦ä¹ å˜åŒ–
        strategy_growth = post_strategies - pre_strategies
        concept_growth = post_concepts - pre_concepts
        if strategy_growth > 0 or concept_growth > 0:
            print(f"ğŸ“ˆ å­¦ä¹ å¢é•¿: +{strategy_growth}ç­–ç•¥ +{concept_growth}æ¦‚å¿µ")
        
        # è®°å½•å­¦ä¹ å†ç¨‹
        learning_journey.append({
            'stage': (i-1)//3 + 1,
            'task_num': i,
            'task': task,
            'action': result['action'],
            'success': result['success'],
            'reward': result['reward'],
            'strategies': post_strategies,
            'concepts': post_concepts,
            'success_rate': post_performance.get('current_success_rate', 0)
        })
        
        # é˜¶æ®µæ€§è¿›åŒ–å±•ç¤º
        if i % 3 == 0:
            print(f"\nğŸ§  ç¬¬{(i-1)//3 + 1}é˜¶æ®µå®Œæˆ - è¿›åŒ–æ€»ç»“:")
            stage_performance = agent.get_performance_summary()
            print(f"  å½“å‰æˆåŠŸç‡: {stage_performance['current_success_rate']:.1%}")
            print(f"  ç­–ç•¥åº“è§„æ¨¡: {stage_performance['strategies_count']}")
            print(f"  çŸ¥è¯†æ¦‚å¿µæ•°: {stage_performance['knowledge_concepts']}")
            print(f"  æ¢ç´¢ç‡: {stage_performance['exploration_rate']:.2f}")
            
            # æ˜¾ç¤ºæœ€æœ‰æ•ˆçš„ç­–ç•¥
            effective_strategies = []
            for name, strategy in agent.strategies.items():
                if strategy.usage_count > 0 and strategy.success_rate > 0.5:
                    effective_strategies.append((name, strategy.success_rate, strategy.usage_count))
            
            if effective_strategies:
                effective_strategies.sort(key=lambda x: x[1], reverse=True)
                print(f"  ğŸ† æœ€ä½³ç­–ç•¥: {effective_strategies[0][0][:30]}... (æˆåŠŸç‡{effective_strategies[0][1]:.1%})")
            
            # è§¦å‘æ·±åº¦è¿›åŒ–
            if i % 6 == 0:
                print(f"  ğŸ”„ è§¦å‘æ·±åº¦è¿›åŒ–...")
                agent.self_evolve()
            
            print()
        else:
            print()
    
    # æœ€ç»ˆå­¦ä¹ åˆ†æ
    print("=" * 60)
    print("ğŸ“ æœ€ç»ˆå­¦ä¹ åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    final_performance = agent.get_performance_summary()
    
    print(f"\nğŸ“Š æ•´ä½“è¡¨ç°:")
    print(f"  æ€»å¤„ç†ä»»åŠ¡: {final_performance['total_tasks']}")
    print(f"  æœ€ç»ˆæˆåŠŸç‡: {final_performance['current_success_rate']:.1%}")
    print(f"  æ€§èƒ½è¶‹åŠ¿: {final_performance['trend']}")
    
    print(f"\nğŸ§  çŸ¥è¯†è·å¾—:")
    print(f"  å­¦ä¼šç­–ç•¥æ•°: {final_performance['strategies_count']}")
    print(f"  æŒæ¡æ¦‚å¿µæ•°: {final_performance['knowledge_concepts']}")
    print(f"  ç»éªŒç§¯ç´¯æ•°: {final_performance['experiences_count']}")
    
    # åˆ†æå­¦ä¹ æ›²çº¿
    print(f"\nğŸ“ˆ å­¦ä¹ æ›²çº¿åˆ†æ:")
    success_rates = [entry['success_rate'] for entry in learning_journey]
    
    if len(success_rates) >= 5:
        early_avg = sum(success_rates[:5]) / 5
        late_avg = sum(success_rates[-5:]) / 5
        improvement = late_avg - early_avg
        
        print(f"  æ—©æœŸå¹³å‡æˆåŠŸç‡: {early_avg:.1%}")
        print(f"  åæœŸå¹³å‡æˆåŠŸç‡: {late_avg:.1%}")
        print(f"  å­¦ä¹ æ”¹è¿›å¹…åº¦: {improvement:+.1%}")
        
        if improvement > 0.1:
            print("  ğŸš€ æ˜¾è‘—è¿›æ­¥ï¼Agentå±•ç°å‡ºå¼ºå¤§çš„å­¦ä¹ èƒ½åŠ›")
        elif improvement > 0:
            print("  ğŸ“Š ç¨³æ­¥æå‡ï¼Œå­¦ä¹ è¿‡ç¨‹æœ‰æ•ˆ")
        else:
            print("  ğŸ¤” éœ€è¦è°ƒæ•´å­¦ä¹ ç­–ç•¥")
    
    # ç­–ç•¥è¿›åŒ–åˆ†æ
    print(f"\nğŸ”¬ ç­–ç•¥è¿›åŒ–åˆ†æ:")
    strategy_performance = []
    for name, strategy in agent.strategies.items():
        if strategy.usage_count > 0:
            strategy_performance.append({
                'name': name,
                'success_rate': strategy.success_rate,
                'usage_count': strategy.usage_count,
                'efficiency': strategy.success_rate * strategy.usage_count
            })
    
    # æŒ‰æ•ˆç‡æ’åº
    strategy_performance.sort(key=lambda x: x['efficiency'], reverse=True)
    
    print(f"  æœ€é«˜æ•ˆç­–ç•¥å‰3å:")
    for i, strategy in enumerate(strategy_performance[:3], 1):
        print(f"    {i}. {strategy['name'][:40]}...")
        print(f"       æˆåŠŸç‡: {strategy['success_rate']:.1%} | ä½¿ç”¨æ¬¡æ•°: {strategy['usage_count']}")
    
    # è¡Œä¸ºæ¨¡å¼åˆ†æ
    print(f"\nğŸ¯ è¡Œä¸ºæ¨¡å¼åˆ†æ:")
    action_stats = {}
    for exp in agent.experiences:
        action = exp.action
        if action not in action_stats:
            action_stats[action] = {'total': 0, 'success': 0}
        action_stats[action]['total'] += 1
        if exp.success:
            action_stats[action]['success'] += 1
    
    for action, stats in action_stats.items():
        success_rate = stats['success'] / stats['total'] if stats['total'] > 0 else 0
        print(f"  {action}: {success_rate:.1%} æˆåŠŸç‡ ({stats['success']}/{stats['total']}æ¬¡)")
    
    # ä¿å­˜è¯¦ç»†çŠ¶æ€
    timestamp = int(time.time())
    state_file = f"advanced_agent_state_{timestamp}.json"
    agent.save_state(state_file)
    
    # ä¿å­˜å­¦ä¹ å†ç¨‹
    journey_file = f"learning_journey_{timestamp}.json"
    with open(journey_file, 'w', encoding='utf-8') as f:
        json.dump(learning_journey, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜:")
    print(f"  AgentçŠ¶æ€: {state_file}")
    print(f"  å­¦ä¹ å†ç¨‹: {journey_file}")
    
    return agent, learning_journey

def analyze_learning_patterns(journey):
    """åˆ†æå­¦ä¹ æ¨¡å¼"""
    print("\nğŸ” æ·±åº¦å­¦ä¹ æ¨¡å¼åˆ†æ:")
    
    # æŒ‰é˜¶æ®µåˆ†æ
    stages = {}
    for entry in journey:
        stage = entry['stage']
        if stage not in stages:
            stages[stage] = []
        stages[stage].append(entry)
    
    for stage_num, stage_data in stages.items():
        stage_success_rate = sum(1 for x in stage_data if x['success']) / len(stage_data)
        avg_reward = sum(x['reward'] for x in stage_data) / len(stage_data)
        actions_used = set(x['action'] for x in stage_data)
        
        print(f"  é˜¶æ®µ {stage_num}:")
        print(f"    æˆåŠŸç‡: {stage_success_rate:.1%}")
        print(f"    å¹³å‡å¥–åŠ±: {avg_reward:.2f}")
        print(f"    ä½¿ç”¨åŠ¨ä½œ: {', '.join(actions_used)}")
    
    # é€‚åº”æ€§åˆ†æ
    print(f"\nğŸ¨ é€‚åº”æ€§åˆ†æ:")
    action_diversity = len(set(entry['action'] for entry in journey))
    task_diversity = len(set(entry['task'] for entry in journey))
    
    print(f"  åŠ¨ä½œå¤šæ ·æ€§: {action_diversity} ç§ä¸åŒåŠ¨ä½œ")
    print(f"  ä»»åŠ¡å¤šæ ·æ€§: {task_diversity} ç§ä¸åŒä»»åŠ¡")
    
    adaptation_score = action_diversity / task_diversity if task_diversity > 0 else 0
    print(f"  é€‚åº”æ€§è¯„åˆ†: {adaptation_score:.2f} (è¶Šæ¥è¿‘1è¶Šå¥½)")

if __name__ == "__main__":
    # è¿è¡Œé«˜çº§æ¼”ç¤º
    agent, journey = advanced_agent_demo()
    
    # æ·±åº¦åˆ†æ
    analyze_learning_patterns(journey)
    
    print(f"\nğŸ‰ é«˜çº§è‡ªè¿›åŒ–Agentæ¼”ç¤ºå®Œæˆï¼")
    print(f"Agentå±•ç°äº†ä»æ¢ç´¢åˆ°ä¸“ç²¾çš„å®Œæ•´å­¦ä¹ è¿‡ç¨‹ã€‚")