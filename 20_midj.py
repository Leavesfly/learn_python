"""
ç®€å•ç‰ˆMidjourneyå›¾åƒç”Ÿæˆç³»ç»Ÿ
å±±æ³½ - 2025å¹´å®ç°

è¿™ä¸ªç³»ç»Ÿå®ç°äº†ç±»ä¼¼Midjourneyçš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ–‡æœ¬åˆ°å›¾åƒçš„ç”Ÿæˆ
2. æç¤ºè¯ä¼˜åŒ–å’Œå¤„ç†
3. å¤šç§è‰ºæœ¯é£æ ¼æ”¯æŒ
4. å›¾åƒåå¤„ç†å’Œå¢å¼º
5. ç®€å•çš„ç”¨æˆ·ç•Œé¢
"""

import os
import json
import time
import hashlib
import asyncio
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from pathlib import Path
import random

# æ ¸å¿ƒä¾èµ–åº“
try:
    import torch
    import torch.nn as nn
    from PIL import Image, ImageEnhance, ImageFilter
    import numpy as np
    from transformers import pipeline
    import requests
    from io import BytesIO
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False
    print("è­¦å‘Š: PyTorchç›¸å…³ä¾èµ–æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")

class PromptProcessor:
    """æç¤ºè¯å¤„ç†å™¨ - ä¼˜åŒ–å’Œå¢å¼ºç”¨æˆ·è¾“å…¥çš„æç¤ºè¯"""
    
    def __init__(self):
        # è‰ºæœ¯é£æ ¼å…³é”®è¯
        self.art_styles = {
            "realistic": "photorealistic, highly detailed, 8k resolution",
            "anime": "anime style, manga, cel shading, vibrant colors",
            "oil_painting": "oil painting, traditional art, textured brushstrokes",
            "watercolor": "watercolor painting, soft edges, flowing colors",
            "digital_art": "digital art, concept art, professional illustration",
            "cyberpunk": "cyberpunk, neon lights, futuristic, dark atmosphere",
            "fantasy": "fantasy art, magical, ethereal, mystical atmosphere",
            "minimalist": "minimalist, clean lines, simple composition",
            "abstract": "abstract art, geometric shapes, modern composition",
            "vintage": "vintage style, retro, nostalgic, aged paper texture"
        }
        
        # è´¨é‡å¢å¼ºå…³é”®è¯
        self.quality_boosters = [
            "masterpiece", "best quality", "ultra detailed", "professional",
            "studio lighting", "sharp focus", "vivid colors", "high resolution"
        ]
        
        # è´Ÿé¢æç¤ºè¯
        self.negative_prompts = [
            "blurry", "low quality", "pixelated", "distorted", "ugly",
            "bad anatomy", "deformed", "artifacts", "noise", "oversaturated"
        ]
    
    def enhance_prompt(self, user_prompt: str, style: str = "realistic", 
                      quality_level: int = 3) -> Dict[str, str]:
        """å¢å¼ºç”¨æˆ·æç¤ºè¯"""
        # åŸºç¡€æç¤ºè¯å¤„ç†
        enhanced_prompt = user_prompt.strip()
        
        # æ·»åŠ è‰ºæœ¯é£æ ¼
        if style in self.art_styles:
            enhanced_prompt += f", {self.art_styles[style]}"
        
        # æ·»åŠ è´¨é‡å¢å¼ºè¯
        quality_words = random.sample(self.quality_boosters, 
                                    min(quality_level, len(self.quality_boosters)))
        enhanced_prompt += f", {', '.join(quality_words)}"
        
        # ç”Ÿæˆè´Ÿé¢æç¤ºè¯
        negative_prompt = ", ".join(random.sample(self.negative_prompts, 3))
        
        return {
            "positive_prompt": enhanced_prompt,
            "negative_prompt": negative_prompt,
            "original_prompt": user_prompt,
            "style": style
        }
    
    def analyze_prompt(self, prompt: str) -> Dict[str, any]:
        """åˆ†ææç¤ºè¯çš„å¤æ‚åº¦å’Œç‰¹å¾"""
        words = prompt.lower().split()
        
        # åˆ†æä¸»é¢˜ç±»å‹
        themes = {
            "portrait": any(word in words for word in ["person", "face", "portrait", "äººç‰©"]),
            "landscape": any(word in words for word in ["landscape", "nature", "mountain", "é£æ™¯"]),
            "object": any(word in words for word in ["car", "building", "food", "ç‰©ä½“"]),
            "abstract": any(word in words for word in ["abstract", "geometric", "pattern", "æŠ½è±¡"])
        }
        
        return {
            "word_count": len(words),
            "complexity": "high" if len(words) > 10 else "medium" if len(words) > 5 else "low",
            "themes": [theme for theme, present in themes.items() if present],
            "estimated_time": len(words) * 2 + 30  # ä¼°ç®—ç”Ÿæˆæ—¶é—´ï¼ˆç§’ï¼‰
        }

class ImageGenerator:
    """å›¾åƒç”Ÿæˆå™¨ - æ ¸å¿ƒçš„å›¾åƒç”Ÿæˆé€»è¾‘"""
    
    def __init__(self, model_path: str = None):
        self.model_path = model_path
        self.device = "cuda" if torch.cuda.is_available() and HAS_TORCH else "cpu"
        self.model = None
        
        # æ¨¡æ‹Ÿå‚æ•°ï¼ˆå½“æ²¡æœ‰çœŸå®æ¨¡å‹æ—¶ä½¿ç”¨ï¼‰
        self.simulation_mode = not HAS_TORCH
        
        if not self.simulation_mode:
            self._load_model()
    
    def _load_model(self):
        """åŠ è½½å›¾åƒç”Ÿæˆæ¨¡å‹"""
        try:
            # è¿™é‡Œåº”è¯¥åŠ è½½å®é™…çš„Stable Diffusionæ¨¡å‹
            # ç”±äºç‰ˆæƒå’Œè®¡ç®—èµ„æºé™åˆ¶ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
            print(f"æ­£åœ¨åŠ è½½æ¨¡å‹åˆ°è®¾å¤‡: {self.device}")
            # self.model = StableDiffusionPipeline.from_pretrained(...)
            self.simulation_mode = True
            print("ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ç”Ÿæˆå›¾åƒ")
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œåˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ¨¡å¼: {e}")
            self.simulation_mode = True
    
    def generate_image(self, prompt_data: Dict[str, str], 
                      width: int = 512, height: int = 512,
                      steps: int = 20, guidance_scale: float = 7.5) -> Image.Image:
        """ç”Ÿæˆå›¾åƒ"""
        if self.simulation_mode:
            return self._generate_mock_image(prompt_data, width, height)
        
        # å®é™…çš„å›¾åƒç”Ÿæˆé€»è¾‘
        try:
            with torch.no_grad():
                # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„æ¨¡å‹ç”Ÿæˆ
                # image = self.model(
                #     prompt=prompt_data["positive_prompt"],
                #     negative_prompt=prompt_data["negative_prompt"],
                #     width=width,
                #     height=height,
                #     num_inference_steps=steps,
                #     guidance_scale=guidance_scale
                # ).images[0]
                
                # æ¨¡æ‹Ÿç”Ÿæˆè¿‡ç¨‹
                return self._generate_mock_image(prompt_data, width, height)
        except Exception as e:
            print(f"å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_mock_image(prompt_data, width, height)
    
    def _generate_mock_image(self, prompt_data: Dict[str, str], 
                           width: int, height: int) -> Image.Image:
        """ç”Ÿæˆæ¨¡æ‹Ÿå›¾åƒï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        # åˆ›å»ºä¸€ä¸ªå½©è‰²æ¸å˜å›¾åƒä½œä¸ºæ¨¡æ‹Ÿç»“æœ
        image = Image.new('RGB', (width, height))
        pixels = []
        
        # æ ¹æ®æç¤ºè¯çš„å“ˆå¸Œå€¼ç”Ÿæˆä¸åŒçš„é¢œè‰²
        prompt_hash = hashlib.md5(prompt_data["positive_prompt"].encode()).hexdigest()
        r_base = int(prompt_hash[:2], 16)
        g_base = int(prompt_hash[2:4], 16)
        b_base = int(prompt_hash[4:6], 16)
        
        for y in range(height):
            for x in range(width):
                # åˆ›å»ºæ¸å˜æ•ˆæœ
                r = int(r_base * (1 - x/width) + (255-r_base) * (x/width))
                g = int(g_base * (1 - y/height) + (255-g_base) * (y/height))
                b = int((r_base + g_base) / 2 * (1 - ((x+y)/(width+height))))
                pixels.append((r % 256, g % 256, b % 256))
        
        image.putdata(pixels)
        
        # æ·»åŠ ä¸€äº›ç®€å•çš„å‡ ä½•å½¢çŠ¶æ¥æ¨¡æ‹Ÿå†…å®¹
        from PIL import ImageDraw
        draw = ImageDraw.Draw(image)
        
        # æ ¹æ®æç¤ºè¯æ·»åŠ ä¸åŒå½¢çŠ¶
        if "circle" in prompt_data["positive_prompt"].lower():
            draw.ellipse([width//4, height//4, 3*width//4, 3*height//4], 
                        fill=(255, 255, 255), outline=(0, 0, 0))
        elif "square" in prompt_data["positive_prompt"].lower():
            draw.rectangle([width//4, height//4, 3*width//4, 3*height//4], 
                         fill=(255, 255, 255), outline=(0, 0, 0))
        
        return image

class ImagePostProcessor:
    """å›¾åƒåå¤„ç†å™¨ - å¯¹ç”Ÿæˆçš„å›¾åƒè¿›è¡Œå¢å¼ºå’Œé£æ ¼åŒ–"""
    
    def __init__(self):
        self.filters = {
            "enhance": self._enhance_image,
            "vintage": self._apply_vintage_filter,
            "dramatic": self._apply_dramatic_filter,
            "soft": self._apply_soft_filter,
            "sharpen": self._apply_sharpen_filter
        }
    
    def process_image(self, image: Image.Image, 
                     processing_options: List[str]) -> Image.Image:
        """å¯¹å›¾åƒåº”ç”¨åå¤„ç†æ•ˆæœ"""
        processed_image = image.copy()
        
        for option in processing_options:
            if option in self.filters:
                processed_image = self.filters[option](processed_image)
        
        return processed_image
    
    def _enhance_image(self, image: Image.Image) -> Image.Image:
        """å¢å¼ºå›¾åƒå¯¹æ¯”åº¦å’Œé¥±å’Œåº¦"""
        # å¢å¼ºå¯¹æ¯”åº¦
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.2)
        
        # å¢å¼ºé¥±å’Œåº¦
        enhancer = ImageEnhance.Color(image)
        image = enhancer.enhance(1.1)
        
        # è½»å¾®é”åŒ–
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(1.1)
        
        return image
    
    def _apply_vintage_filter(self, image: Image.Image) -> Image.Image:
        """åº”ç”¨å¤å¤æ»¤é•œ"""
        # é™ä½é¥±å’Œåº¦
        enhancer = ImageEnhance.Color(image)
        image = enhancer.enhance(0.7)
        
        # æ·»åŠ æ£•è¤è‰²è°ƒ
        pixels = list(image.getdata())
        vintage_pixels = []
        
        for r, g, b in pixels:
            # æ£•è¤è‰²è°ƒè½¬æ¢
            tr = int(0.393 * r + 0.769 * g + 0.189 * b)
            tg = int(0.349 * r + 0.686 * g + 0.168 * b)
            tb = int(0.272 * r + 0.534 * g + 0.131 * b)
            
            vintage_pixels.append((min(255, tr), min(255, tg), min(255, tb)))
        
        image.putdata(vintage_pixels)
        return image
    
    def _apply_dramatic_filter(self, image: Image.Image) -> Image.Image:
        """åº”ç”¨æˆå‰§æ€§æ»¤é•œ"""
        # å¢å¼ºå¯¹æ¯”åº¦
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.5)
        
        # å¢å¼ºé¥±å’Œåº¦
        enhancer = ImageEnhance.Color(image)
        image = enhancer.enhance(1.3)
        
        return image
    
    def _apply_soft_filter(self, image: Image.Image) -> Image.Image:
        """åº”ç”¨æŸ”å’Œæ»¤é•œ"""
        # è½»å¾®æ¨¡ç³Š
        image = image.filter(ImageFilter.GaussianBlur(radius=0.5))
        
        # é™ä½å¯¹æ¯”åº¦
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(0.9)
        
        return image
    
    def _apply_sharpen_filter(self, image: Image.Image) -> Image.Image:
        """åº”ç”¨é”åŒ–æ»¤é•œ"""
        # é”åŒ–
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(1.5)
        
        return image

class GenerationTask:
    """ç”Ÿæˆä»»åŠ¡ - è¡¨ç¤ºä¸€ä¸ªå›¾åƒç”Ÿæˆè¯·æ±‚"""
    
    def __init__(self, prompt: str, style: str = "realistic", 
                 width: int = 512, height: int = 512):
        self.id = hashlib.md5(f"{prompt}{time.time()}".encode()).hexdigest()[:8]
        self.prompt = prompt
        self.style = style
        self.width = width
        self.height = height
        self.status = "pending"  # pending, processing, completed, failed
        self.created_at = datetime.now()
        self.completed_at = None
        self.result_path = None
        self.error_message = None
        self.progress = 0

class SimpleMidjourney:
    """ç®€å•ç‰ˆMidjourneyä¸»ç±» - æ•´åˆæ‰€æœ‰åŠŸèƒ½æ¨¡å—"""
    
    def __init__(self, output_dir: str = "generated_images"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.prompt_processor = PromptProcessor()
        self.image_generator = ImageGenerator()
        self.post_processor = ImagePostProcessor()
        
        # ä»»åŠ¡ç®¡ç†
        self.tasks = {}
        self.task_history = []
        
        print("ç®€å•ç‰ˆMidjourneyåˆå§‹åŒ–å®Œæˆï¼")
        print(f"å›¾åƒè¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ä½¿ç”¨è®¾å¤‡: {self.image_generator.device}")
    
    async def generate_async(self, prompt: str, style: str = "realistic",
                           width: int = 512, height: int = 512,
                           post_processing: List[str] = None) -> GenerationTask:
        """å¼‚æ­¥ç”Ÿæˆå›¾åƒ"""
        # åˆ›å»ºç”Ÿæˆä»»åŠ¡
        task = GenerationTask(prompt, style, width, height)
        self.tasks[task.id] = task
        
        print(f"å¼€å§‹ç”Ÿæˆä»»åŠ¡ {task.id}: {prompt[:50]}...")
        
        try:
            # æ›´æ–°çŠ¶æ€
            task.status = "processing"
            task.progress = 10
            
            # å¤„ç†æç¤ºè¯
            prompt_data = self.prompt_processor.enhance_prompt(prompt, style)
            print(f"å¢å¼ºåçš„æç¤ºè¯: {prompt_data['positive_prompt'][:100]}...")
            
            task.progress = 20
            await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            # ç”Ÿæˆå›¾åƒ
            print("æ­£åœ¨ç”Ÿæˆå›¾åƒ...")
            task.progress = 50
            
            image = self.image_generator.generate_image(
                prompt_data, width, height
            )
            
            task.progress = 80
            await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿç”Ÿæˆæ—¶é—´
            
            # åå¤„ç†
            if post_processing:
                print(f"åº”ç”¨åå¤„ç†æ•ˆæœ: {post_processing}")
                image = self.post_processor.process_image(image, post_processing)
            
            task.progress = 90
            
            # ä¿å­˜å›¾åƒ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{task.id}_{timestamp}_{style}.png"
            filepath = self.output_dir / filename
            
            image.save(filepath, "PNG")
            
            # å®Œæˆä»»åŠ¡
            task.status = "completed"
            task.progress = 100
            task.completed_at = datetime.now()
            task.result_path = str(filepath)
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.task_history.append(task)
            
            print(f"å›¾åƒç”Ÿæˆå®Œæˆ: {filepath}")
            return task
            
        except Exception as e:
            task.status = "failed"
            task.error_message = str(e)
            print(f"ç”Ÿæˆå¤±è´¥: {e}")
            return task
    
    def generate(self, prompt: str, **kwargs) -> GenerationTask:
        """åŒæ­¥ç”Ÿæˆå›¾åƒ"""
        return asyncio.run(self.generate_async(prompt, **kwargs))
    
    def get_task_status(self, task_id: str) -> Optional[GenerationTask]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        return self.tasks.get(task_id)
    
    def list_generated_images(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰ç”Ÿæˆçš„å›¾åƒ"""
        images = []
        for task in self.task_history:
            if task.status == "completed" and task.result_path:
                images.append({
                    "id": task.id,
                    "prompt": task.prompt,
                    "style": task.style,
                    "path": task.result_path,
                    "created_at": task.created_at.isoformat(),
                    "size": f"{task.width}x{task.height}"
                })
        return images
    
    def create_gallery_html(self) -> str:
        """åˆ›å»ºå›¾åƒç”»å»ŠHTMLé¡µé¢"""
        images = self.list_generated_images()
        
        html = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>ç®€å•ç‰ˆMidjourney - å›¾åƒç”»å»Š</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; background: #f0f0f0; }
                .header { text-align: center; margin-bottom: 30px; }
                .gallery { display: grid; grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); gap: 20px; }
                .image-card { 
                    background: white; 
                    border-radius: 8px; 
                    padding: 15px; 
                    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                }
                .image-card img { width: 100%; height: 300px; object-fit: cover; border-radius: 4px; }
                .image-info { margin-top: 10px; }
                .prompt { font-weight: bold; color: #333; margin-bottom: 8px; }
                .meta { font-size: 12px; color: #666; }
                .style-tag { 
                    background: #007bff; 
                    color: white; 
                    padding: 2px 8px; 
                    border-radius: 12px; 
                    font-size: 11px;
                    display: inline-block;
                    margin-top: 5px;
                }
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ğŸ¨ ç®€å•ç‰ˆMidjourneyç”»å»Š</h1>
                <p>AIç”Ÿæˆçš„è‰ºæœ¯ä½œå“å±•ç¤º</p>
            </div>
            <div class="gallery">
        """
        
        for img in images:
            html += f"""
                <div class="image-card">
                    <img src="{img['path']}" alt="{img['prompt'][:50]}">
                    <div class="image-info">
                        <div class="prompt">"{img['prompt'][:100]}{'...' if len(img['prompt']) > 100 else ''}"</div>
                        <div class="meta">
                            ID: {img['id']} | å°ºå¯¸: {img['size']} | åˆ›å»ºæ—¶é—´: {img['created_at'][:16]}
                        </div>
                        <span class="style-tag">{img['style']}</span>
                    </div>
                </div>
            """
        
        html += """
            </div>
        </body>
        </html>
        """
        
        gallery_path = self.output_dir / "gallery.html"
        with open(gallery_path, 'w', encoding='utf-8') as f:
            f.write(html)
        
        print(f"ç”»å»Šé¡µé¢å·²ç”Ÿæˆ: {gallery_path}")
        return str(gallery_path)

def demo_simple_midjourney():
    """æ¼”ç¤ºç®€å•ç‰ˆMidjourneyçš„åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ¨ ç®€å•ç‰ˆMidjourneyæ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºMidjourneyå®ä¾‹
    mj = SimpleMidjourney()
    
    # æ¼”ç¤ºæç¤ºè¯
    demo_prompts = [
        ("ä¸€åªå¯çˆ±çš„å°çŒ«åœ¨èŠ±å›­é‡Œç©è€ï¼Œé˜³å…‰é€è¿‡æ ‘å¶æ´’ä¸‹", "realistic"),
        ("æœªæ¥åŸå¸‚çš„å¤œæ™¯ï¼Œéœ“è™¹ç¯é—ªçƒ", "cyberpunk"),
        ("å®é™çš„å±±æ°´ç”»ï¼Œæ°´å¢¨é£æ ¼", "watercolor"),
        ("æŠ½è±¡çš„å‡ ä½•å›¾å½¢ï¼Œç°ä»£è‰ºæœ¯é£æ ¼", "abstract"),
        ("å¤å¤çš„å’–å•¡å…åœºæ™¯ï¼Œæ¸©æš–çš„ç¯å…‰", "vintage")
    ]
    
    print("\næ­£åœ¨ç”Ÿæˆæ¼”ç¤ºå›¾åƒ...")
    print("-" * 40)
    
    # ç”Ÿæˆå›¾åƒ
    for i, (prompt, style) in enumerate(demo_prompts):
        print(f"\n{i+1}. æç¤ºè¯: {prompt}")
        print(f"   é£æ ¼: {style}")
        
        # é€‰æ‹©åå¤„ç†æ•ˆæœ
        post_effects = ["enhance"] if i % 2 == 0 else ["enhance", "soft"]
        
        task = mj.generate(
            prompt=prompt,
            style=style,
            width=512,
            height=512,
            post_processing=post_effects
        )
        
        if task.status == "completed":
            print(f"   âœ… ç”ŸæˆæˆåŠŸ: {task.result_path}")
        else:
            print(f"   âŒ ç”Ÿæˆå¤±è´¥: {task.error_message}")
    
    # ç”Ÿæˆç”»å»Šé¡µé¢
    print("\n" + "-" * 40)
    print("ğŸ“± ç”Ÿæˆå›¾åƒç”»å»Š...")
    gallery_path = mj.create_gallery_html()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    images = mj.list_generated_images()
    print(f"\nğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
    print(f"   æ€»ç”Ÿæˆå›¾åƒæ•°: {len(images)}")
    print(f"   è¾“å‡ºç›®å½•: {mj.output_dir}")
    print(f"   ç”»å»Šé¡µé¢: {gallery_path}")
    
    # æ˜¾ç¤ºç”Ÿæˆçš„å›¾åƒåˆ—è¡¨
    print(f"\nğŸ–¼ï¸  ç”Ÿæˆçš„å›¾åƒ:")
    for img in images:
        print(f"   â€¢ {img['id']}: {img['prompt'][:40]}... ({img['style']})")
    
    print(f"\nâœ¨ æ¼”ç¤ºå®Œæˆï¼è¯·æŸ¥çœ‹è¾“å‡ºç›®å½•ä¸­çš„å›¾åƒå’Œç”»å»Šé¡µé¢ã€‚")
    
    return mj

# é«˜çº§åŠŸèƒ½ç±»
class AdvancedFeatures:
    """é«˜çº§åŠŸèƒ½æ¨¡å—"""
    
    def __init__(self, midjourney_instance):
        self.mj = midjourney_instance
    
    def batch_generate(self, prompts: List[Dict], max_concurrent: int = 3):
        """æ‰¹é‡ç”Ÿæˆå›¾åƒ"""
        print(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆ {len(prompts)} å¼ å›¾åƒ...")
        
        async def run_batch():
            semaphore = asyncio.Semaphore(max_concurrent)
            
            async def generate_single(prompt_data):
                async with semaphore:
                    return await self.mj.generate_async(**prompt_data)
            
            tasks = [generate_single(p) for p in prompts]
            results = await asyncio.gather(*tasks)
            return results
        
        return asyncio.run(run_batch())
    
    def create_variations(self, base_prompt: str, count: int = 4):
        """åŸºäºåŸºç¡€æç¤ºè¯åˆ›å»ºå˜ä½“"""
        variations = []
        style_variants = ["realistic", "anime", "oil_painting", "digital_art"]
        
        for i in range(count):
            style = style_variants[i % len(style_variants)]
            # æ·»åŠ éšæœºå˜åŒ–è¯
            variation_words = ["detailed", "vibrant", "atmospheric", "cinematic"]
            variation = f"{base_prompt}, {random.choice(variation_words)}"
            
            variations.append({
                "prompt": variation,
                "style": style,
                "width": 512,
                "height": 512
            })
        
        return self.batch_generate(variations)
    
    def upscale_image(self, image_path: str, scale_factor: int = 2):
        """æ”¾å¤§å›¾åƒï¼ˆç®€å•å®ç°ï¼‰"""
        try:
            image = Image.open(image_path)
            new_size = (image.width * scale_factor, image.height * scale_factor)
            upscaled = image.resize(new_size, Image.Resampling.LANCZOS)
            
            # ä¿å­˜æ”¾å¤§åçš„å›¾åƒ
            path = Path(image_path)
            new_path = path.parent / f"{path.stem}_upscaled{path.suffix}"
            upscaled.save(new_path)
            
            print(f"å›¾åƒå·²æ”¾å¤§: {new_path}")
            return str(new_path)
        except Exception as e:
            print(f"å›¾åƒæ”¾å¤§å¤±è´¥: {e}")
            return None

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ç®€å•ç‰ˆMidjourneyç³»ç»Ÿ...")
    
    # è¿è¡Œæ¼”ç¤º
    mj_instance = demo_simple_midjourney()
    
    # æ¼”ç¤ºé«˜çº§åŠŸèƒ½
    print("\n" + "=" * 60)
    print("ğŸ”¥ é«˜çº§åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    advanced = AdvancedFeatures(mj_instance)
    
    # æ¼”ç¤ºå˜ä½“ç”Ÿæˆ
    print("\nç”Ÿæˆæç¤ºè¯å˜ä½“...")
    base_prompt = "ä¸€åº§ç¥ç§˜çš„å¤å ¡åœ¨æœˆå…‰ä¸‹"
    variations = advanced.create_variations(base_prompt, count=3)
    
    print(f"å˜ä½“ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len([v for v in variations if v.status == 'completed'])} å¼ å›¾åƒ")
    
    # æœ€ç»ˆç”»å»Šæ›´æ–°
    final_gallery = mj_instance.create_gallery_html()
    print(f"\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
    print(f"æœ€ç»ˆç”»å»Š: {final_gallery}")
    print(f"æ€»å…±ç”Ÿæˆå›¾åƒ: {len(mj_instance.list_generated_images())} å¼ ")