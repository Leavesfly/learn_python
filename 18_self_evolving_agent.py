"""
è‡ªè¿›åŒ–è‡ªå­¦ä¹ Agentå®ç°
ä½œè€…ï¼šå±±æ³½

è¿™ä¸ªAgentå…·æœ‰ä»¥ä¸‹è‡ªè¿›åŒ–èƒ½åŠ›ï¼š
1. ç»éªŒè®°å¿†å’Œå­¦ä¹ 
2. ç­–ç•¥è‡ªåŠ¨ä¼˜åŒ–
3. åæ€å’Œæ”¹è¿›æœºåˆ¶
4. çŸ¥è¯†å›¾è°±æ„å»º
5. åŠ¨æ€å·¥å…·å­¦ä¹ 
"""

import json
import time
import random
import hashlib
from typing import Dict, List, Any, Optional, Tuple, Callable
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
# import numpy as np  # å¦‚æœéœ€è¦numpyï¼Œè¯·å…ˆå®‰è£…: pip install numpy
try:
    import numpy as np
except ImportError:
    print("è­¦å‘Š: numpyæœªå®‰è£…ï¼Œä½¿ç”¨å†…ç½®æ›¿ä»£æ–¹æ¡ˆ")
    import random
    import math
    
    class MockLinalg:
        def norm(self, vector):
            return math.sqrt(sum(x*x for x in vector))
    
    class MockRandom:
        def rand(self, size):
            return [random.random() for _ in range(size)]
    
    class MockNumpy:
        def __init__(self):
            self.random = MockRandom()
            self.linalg = MockLinalg()
            
        def mean(self, data):
            return sum(data) / len(data) if data else 0
            
        def dot(self, a, b):
            return sum(x*y for x,y in zip(a,b))
    
    np = MockNumpy()
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class Experience:
    """ç»éªŒè®°å½•"""
    task: str
    context: Dict[str, Any]
    action: str
    result: Any
    success: bool
    reward: float
    timestamp: float
    reflection: Optional[str] = None
    
    def to_dict(self):
        return asdict(self)

@dataclass
class Strategy:
    """ç­–ç•¥è®°å½•"""
    name: str
    description: str
    conditions: Dict[str, Any]
    actions: List[str]
    success_rate: float
    usage_count: int
    last_updated: float
    
    def to_dict(self):
        return asdict(self)

class KnowledgeGraph:
    """çŸ¥è¯†å›¾è°±ç®¡ç†"""
    
    def __init__(self):
        self.nodes = {}  # æ¦‚å¿µèŠ‚ç‚¹
        self.edges = {}  # å…³ç³»è¾¹
        self.node_embeddings = {}  # èŠ‚ç‚¹åµŒå…¥å‘é‡
        
    def add_concept(self, concept: str, properties: Dict[str, Any]):
        """æ·»åŠ æ¦‚å¿µèŠ‚ç‚¹"""
        self.nodes[concept] = {
            'properties': properties,
            'created_at': time.time(),
            'access_count': 0
        }
        # ç”Ÿæˆç®€å•çš„åµŒå…¥å‘é‡ï¼ˆå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨æ›´å¤æ‚çš„æ–¹æ³•ï¼‰
        self.node_embeddings[concept] = np.random.rand(128)
        
    def add_relation(self, from_concept: str, to_concept: str, relation: str, weight: float = 1.0):
        """æ·»åŠ å…³ç³»è¾¹"""
        if from_concept not in self.edges:
            self.edges[from_concept] = {}
        if to_concept not in self.edges[from_concept]:
            self.edges[from_concept][to_concept] = {}
        
        self.edges[from_concept][to_concept][relation] = {
            'weight': weight,
            'created_at': time.time()
        }
        
    def find_related_concepts(self, concept: str, max_distance: int = 2) -> List[str]:
        """æ‰¾åˆ°ç›¸å…³æ¦‚å¿µ"""
        if concept not in self.nodes:
            return []
            
        visited = set()
        queue = deque([(concept, 0)])
        related = []
        
        while queue:
            current, distance = queue.popleft()
            if current in visited or distance > max_distance:
                continue
                
            visited.add(current)
            if distance > 0:
                related.append(current)
                
            # æ·»åŠ é‚»æ¥èŠ‚ç‚¹
            if current in self.edges:
                for neighbor in self.edges[current]:
                    if neighbor not in visited:
                        queue.append((neighbor, distance + 1))
                        
        return related
        
    def get_concept_similarity(self, concept1: str, concept2: str) -> float:
        """è®¡ç®—æ¦‚å¿µç›¸ä¼¼åº¦"""
        if concept1 not in self.node_embeddings or concept2 not in self.node_embeddings:
            return 0.0
            
        vec1 = self.node_embeddings[concept1]
        vec2 = self.node_embeddings[concept2]
        
        # ä½™å¼¦ç›¸ä¼¼åº¦
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
            
        return dot_product / (norm1 * norm2)

class ReflectionModule:
    """åæ€æ¨¡å—"""
    
    def __init__(self):
        self.reflection_history = []
        
    def reflect_on_experience(self, experience: Experience) -> str:
        """å¯¹ç»éªŒè¿›è¡Œåæ€"""
        reflection_prompts = [
            f"ä¸ºä»€ä¹ˆä»»åŠ¡ '{experience.task}' çš„ç»“æœæ˜¯ {'æˆåŠŸ' if experience.success else 'å¤±è´¥'}ï¼Ÿ",
            f"åœ¨å¤„ç† '{experience.task}' æ—¶ï¼Œæˆ‘å¯ä»¥å¦‚ä½•æ”¹è¿›ï¼Ÿ",
            f"è¿™æ¬¡ç»éªŒæ•™ä¼šäº†æˆ‘ä»€ä¹ˆå…³äº '{experience.task}' çš„æ–°çŸ¥è¯†ï¼Ÿ"
        ]
        
        # ç®€åŒ–ç‰ˆåæ€ï¼ˆå®é™…åº”ç”¨ä¸­ä¼šè°ƒç”¨LLMï¼‰
        if experience.success:
            reflection = f"æˆåŠŸå®Œæˆä»»åŠ¡çš„å…³é”®å› ç´ ï¼š{experience.action}åœ¨ä¸Šä¸‹æ–‡{experience.context}ä¸­è¡¨ç°è‰¯å¥½"
        else:
            reflection = f"å¤±è´¥åŸå› åˆ†æï¼š{experience.action}åœ¨å¤„ç†{experience.task}æ—¶ä¸å¤Ÿæœ‰æ•ˆï¼Œéœ€è¦è°ƒæ•´ç­–ç•¥"
            
        self.reflection_history.append({
            'experience_id': id(experience),
            'reflection': reflection,
            'timestamp': time.time()
        })
        
        return reflection
        
    def identify_patterns(self, recent_experiences: List[Experience]) -> List[str]:
        """è¯†åˆ«ç»éªŒæ¨¡å¼"""
        patterns = []
        
        # æˆåŠŸæ¨¡å¼è¯†åˆ«
        successful_actions = [exp.action for exp in recent_experiences if exp.success]
        if successful_actions:
            action_counts = {}
            for action in successful_actions:
                action_counts[action] = action_counts.get(action, 0) + 1
            
            most_successful = max(action_counts.items(), key=lambda x: x[1])
            patterns.append(f"é«˜æˆåŠŸç‡åŠ¨ä½œæ¨¡å¼ï¼š{most_successful[0]}ï¼ˆæˆåŠŸ{most_successful[1]}æ¬¡ï¼‰")
            
        # å¤±è´¥æ¨¡å¼è¯†åˆ«
        failed_experiences = [exp for exp in recent_experiences if not exp.success]
        if failed_experiences:
            common_failures = {}
            for exp in failed_experiences:
                key = f"{exp.task}:{exp.action}"
                common_failures[key] = common_failures.get(key, 0) + 1
                
            if common_failures:
                most_common_failure = max(common_failures.items(), key=lambda x: x[1])
                patterns.append(f"å¸¸è§å¤±è´¥æ¨¡å¼ï¼š{most_common_failure[0]}ï¼ˆå¤±è´¥{most_common_failure[1]}æ¬¡ï¼‰")
                
        return patterns

class SelfEvolvingAgent:
    """è‡ªè¿›åŒ–Agent"""
    
    def __init__(self, name: str = "SelfEvolvingAgent"):
        self.name = name
        self.experiences = []  # ç»éªŒåº“
        self.strategies = {}   # ç­–ç•¥åº“
        self.knowledge_graph = KnowledgeGraph()
        self.reflection_module = ReflectionModule()
        
        # å­¦ä¹ å‚æ•°
        self.learning_rate = 0.1
        self.exploration_rate = 0.2
        self.memory_size = 1000
        
        # æ€§èƒ½æŒ‡æ ‡
        self.performance_history = []
        self.total_tasks = 0
        self.successful_tasks = 0
        
        # å·¥å…·åº“
        self.available_tools = {
            'search': self._search_tool,
            'calculate': self._calculate_tool,
            'analyze': self._analyze_tool,
            'plan': self._plan_tool
        }
        
        # åˆå§‹åŒ–åŸºç¡€ç­–ç•¥
        self._initialize_base_strategies()
        
    def _initialize_base_strategies(self):
        """åˆå§‹åŒ–åŸºç¡€ç­–ç•¥"""
        base_strategies = [
            Strategy(
                name="æ¢ç´¢ç­–ç•¥",
                description="åœ¨ä¸ç¡®å®šæƒ…å†µä¸‹è¿›è¡Œæ¢ç´¢",
                conditions={"uncertainty": "high"},
                actions=["search", "analyze"],
                success_rate=0.5,
                usage_count=0,
                last_updated=time.time()
            ),
            Strategy(
                name="åˆ©ç”¨ç­–ç•¥", 
                description="ä½¿ç”¨å·²çŸ¥æœ‰æ•ˆçš„æ–¹æ³•",
                conditions={"confidence": "high"},
                actions=["plan", "execute"],
                success_rate=0.8,
                usage_count=0,
                last_updated=time.time()
            )
        ]
        
        for strategy in base_strategies:
            self.strategies[strategy.name] = strategy
            
    def _search_tool(self, query: str) -> Dict[str, Any]:
        """æœç´¢å·¥å…·"""
        # æ¨¡æ‹Ÿæœç´¢ç»“æœ
        return {
            'results': [f"æœç´¢ç»“æœ {i} for {query}" for i in range(3)],
            'confidence': random.uniform(0.5, 1.0)
        }
        
    def _calculate_tool(self, expression: str) -> Dict[str, Any]:
        """è®¡ç®—å·¥å…·"""
        try:
            # ç®€å•çš„æ•°å­¦è¡¨è¾¾å¼è®¡ç®—
            result = eval(expression)
            return {'result': result, 'success': True}
        except:
            return {'result': None, 'success': False}
            
    def _analyze_tool(self, data: Any) -> Dict[str, Any]:
        """åˆ†æå·¥å…·"""
        # æ¨¡æ‹Ÿåˆ†æè¿‡ç¨‹
        return {
            'analysis': f"åˆ†æç»“æœï¼š{data}åŒ…å«{len(str(data))}ä¸ªå­—ç¬¦",
            'insights': ["æ´å¯Ÿ1", "æ´å¯Ÿ2"],
            'confidence': random.uniform(0.6, 0.9)
        }
        
    def _plan_tool(self, goal: str) -> Dict[str, Any]:
        """è§„åˆ’å·¥å…·"""
        # æ¨¡æ‹Ÿè§„åˆ’è¿‡ç¨‹
        steps = [f"æ­¥éª¤{i+1}: å¤„ç†{goal}çš„ç¬¬{i+1}éƒ¨åˆ†" for i in range(3)]
        return {
            'plan': steps,
            'estimated_effort': random.randint(1, 10),
            'success_probability': random.uniform(0.7, 0.95)
        }
        
    def perceive_environment(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç¯å¢ƒæ„ŸçŸ¥"""
        # åˆ†æå½“å‰ç¯å¢ƒçŠ¶æ€
        perception = {
            'current_context': context,
            'relevant_experiences': self._find_relevant_experiences(context),
            'applicable_strategies': self._find_applicable_strategies(context),
            'uncertainty_level': self._assess_uncertainty(context)
        }
        
        return perception
        
    def _find_relevant_experiences(self, context: Dict[str, Any]) -> List[Experience]:
        """æ‰¾åˆ°ç›¸å…³ç»éªŒ"""
        relevant_experiences = []
        
        for exp in self.experiences[-50:]:  # æ£€æŸ¥æœ€è¿‘çš„50ä¸ªç»éªŒ
            similarity = self._calculate_context_similarity(exp.context, context)
            if similarity > 0.5:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                relevant_experiences.append(exp)
                
        return sorted(relevant_experiences, key=lambda x: x.reward, reverse=True)[:10]
        
    def _calculate_context_similarity(self, context1: Dict[str, Any], context2: Dict[str, Any]) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡ç›¸ä¼¼åº¦"""
        common_keys = set(context1.keys()) & set(context2.keys())
        if not common_keys:
            return 0.0
            
        similarity_scores = []
        for key in common_keys:
            if isinstance(context1[key], str) and isinstance(context2[key], str):
                # ç®€å•çš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
                similarity = len(set(context1[key].split()) & set(context2[key].split())) / \
                           len(set(context1[key].split()) | set(context2[key].split()))
                similarity_scores.append(similarity)
            elif context1[key] == context2[key]:
                similarity_scores.append(1.0)
            else:
                similarity_scores.append(0.0)
                
        return np.mean(similarity_scores) if similarity_scores else 0.0
        
    def _find_applicable_strategies(self, context: Dict[str, Any]) -> List[Strategy]:
        """æ‰¾åˆ°é€‚ç”¨çš„ç­–ç•¥"""
        applicable_strategies = []
        
        for strategy in self.strategies.values():
            if self._strategy_matches_context(strategy, context):
                applicable_strategies.append(strategy)
                
        return sorted(applicable_strategies, key=lambda x: x.success_rate, reverse=True)
        
    def _strategy_matches_context(self, strategy: Strategy, context: Dict[str, Any]) -> bool:
        """æ£€æŸ¥ç­–ç•¥æ˜¯å¦åŒ¹é…å½“å‰ä¸Šä¸‹æ–‡"""
        for condition_key, condition_value in strategy.conditions.items():
            if condition_key in context:
                if context[condition_key] != condition_value:
                    return False
            else:
                # å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰è¿™ä¸ªæ¡ä»¶ï¼Œæ ¹æ®ç­–ç•¥ç±»å‹è¿›è¡Œæ¨æ–­
                if condition_key == "uncertainty":
                    uncertainty = self._assess_uncertainty(context)
                    if (condition_value == "high" and uncertainty < 0.5) or \
                       (condition_value == "low" and uncertainty > 0.5):
                        return False
                        
        return True
        
    def _assess_uncertainty(self, context: Dict[str, Any]) -> float:
        """è¯„ä¼°ä¸ç¡®å®šæ€§"""
        # åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯è¯„ä¼°ä¸ç¡®å®šæ€§
        uncertainty_factors = []
        
        # ä»»åŠ¡å¤æ‚åº¦
        task_complexity = len(str(context).split()) / 100.0
        uncertainty_factors.append(min(task_complexity, 1.0))
        
        # ç›¸å…³ç»éªŒæ•°é‡
        relevant_exp_count = len(self._find_relevant_experiences(context))
        experience_factor = max(0.0, 1.0 - relevant_exp_count / 10.0)
        uncertainty_factors.append(experience_factor)
        
        return np.mean(uncertainty_factors)
        
    def decide_action(self, perception: Dict[str, Any]) -> str:
        """å†³ç­–è¡ŒåŠ¨"""
        context = perception['current_context']
        applicable_strategies = perception['applicable_strategies']
        relevant_experiences = perception['relevant_experiences']
        
        # ç­–ç•¥é€‰æ‹©
        if applicable_strategies and random.random() > self.exploration_rate:
            # åˆ©ç”¨ï¼šé€‰æ‹©æœ€ä½³ç­–ç•¥
            best_strategy = applicable_strategies[0]
            action = random.choice(best_strategy.actions)
        else:
            # æ¢ç´¢ï¼šå°è¯•æ–°çš„è¡ŒåŠ¨
            if relevant_experiences:
                # åŸºäºç›¸å…³ç»éªŒé€‰æ‹©
                successful_actions = [exp.action for exp in relevant_experiences if exp.success]
                if successful_actions:
                    action = random.choice(successful_actions)
                else:
                    action = random.choice(list(self.available_tools.keys()))
            else:
                # éšæœºé€‰æ‹©
                action = random.choice(list(self.available_tools.keys()))
                
        return action
        
    def execute_action(self, action: str, context: Dict[str, Any]) -> Any:
        """æ‰§è¡ŒåŠ¨ä½œ"""
        if action in self.available_tools:
            tool = self.available_tools[action]
            
            # æ ¹æ®ä¸Šä¸‹æ–‡å‡†å¤‡å·¥å…·å‚æ•°
            if action == 'search':
                query = context.get('query', 'é»˜è®¤æŸ¥è¯¢')
                return tool(query)
            elif action == 'calculate':
                expression = context.get('expression', '1+1')
                return tool(expression)
            elif action == 'analyze':
                data = context.get('data', context)
                return tool(data)
            elif action == 'plan':
                goal = context.get('goal', 'é»˜è®¤ç›®æ ‡')
                return tool(goal)
            else:
                return tool(str(context))
        else:
            return {'error': f'æœªçŸ¥åŠ¨ä½œ: {action}'}
            
    def evaluate_result(self, result: Any, expected_outcome: Any = None) -> Tuple[bool, float]:
        """è¯„ä¼°ç»“æœ"""
        # ç®€å•çš„ç»“æœè¯„ä¼°é€»è¾‘
        if isinstance(result, dict):
            if 'error' in result:
                return False, -1.0
            elif 'success' in result:
                success = result['success']
                reward = 1.0 if success else -0.5
                return success, reward
            elif 'confidence' in result:
                confidence = result['confidence']
                success = confidence > 0.7
                reward = confidence if success else -0.3
                return success, reward
            else:
                # é»˜è®¤è®¤ä¸ºæœ‰ç»“æœå°±æ˜¯æˆåŠŸ
                return True, 0.5
        else:
            return True, 0.3
            
    def learn_from_experience(self, experience: Experience):
        """ä»ç»éªŒä¸­å­¦ä¹ """
        # æ·»åŠ ç»éªŒåˆ°è®°å¿†åº“
        self.experiences.append(experience)
        
        # é™åˆ¶è®°å¿†åº“å¤§å°
        if len(self.experiences) > self.memory_size:
            self.experiences.pop(0)
            
        # æ›´æ–°çŸ¥è¯†å›¾è°±
        self._update_knowledge_graph(experience)
        
        # åæ€ç»éªŒ
        reflection = self.reflection_module.reflect_on_experience(experience)
        experience.reflection = reflection
        
        # æ›´æ–°æˆ–åˆ›å»ºç­–ç•¥
        self._update_strategies(experience)
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        self.total_tasks += 1
        if experience.success:
            self.successful_tasks += 1
            
        current_success_rate = self.successful_tasks / self.total_tasks
        self.performance_history.append({
            'timestamp': time.time(),
            'success_rate': current_success_rate,
            'total_tasks': self.total_tasks
        })
        
        # è‡ªé€‚åº”å­¦ä¹ ç‡è°ƒæ•´
        self._adjust_learning_parameters()
        
    def _update_knowledge_graph(self, experience: Experience):
        """æ›´æ–°çŸ¥è¯†å›¾è°±"""
        # æå–å…³é”®æ¦‚å¿µ
        task_concept = f"task:{experience.task}"
        action_concept = f"action:{experience.action}"
        
        # æ·»åŠ æˆ–æ›´æ–°æ¦‚å¿µèŠ‚ç‚¹
        self.knowledge_graph.add_concept(task_concept, {
            'type': 'task',
            'description': experience.task,
            'success_count': 0,
            'failure_count': 0
        })
        
        self.knowledge_graph.add_concept(action_concept, {
            'type': 'action', 
            'description': experience.action
        })
        
        # æ·»åŠ å…³ç³»
        relation_type = 'succeeds_with' if experience.success else 'fails_with'
        weight = experience.reward
        
        self.knowledge_graph.add_relation(
            task_concept, action_concept, relation_type, weight
        )
        
    def _update_strategies(self, experience: Experience):
        """æ›´æ–°ç­–ç•¥"""
        task_type = experience.task.split(':')[0] if ':' in experience.task else experience.task
        strategy_name = f"ç­–ç•¥_{task_type}_{experience.action}"
        
        if strategy_name in self.strategies:
            # æ›´æ–°ç°æœ‰ç­–ç•¥
            strategy = self.strategies[strategy_name]
            strategy.usage_count += 1
            
            # æ›´æ–°æˆåŠŸç‡ï¼ˆä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰
            alpha = self.learning_rate
            if experience.success:
                strategy.success_rate = (1 - alpha) * strategy.success_rate + alpha * 1.0
            else:
                strategy.success_rate = (1 - alpha) * strategy.success_rate + alpha * 0.0
                
            strategy.last_updated = time.time()
        else:
            # åˆ›å»ºæ–°ç­–ç•¥
            initial_success_rate = 1.0 if experience.success else 0.0
            new_strategy = Strategy(
                name=strategy_name,
                description=f"é’ˆå¯¹{task_type}ä»»åŠ¡çš„{experience.action}ç­–ç•¥",
                conditions={'task_type': task_type},
                actions=[experience.action],
                success_rate=initial_success_rate,
                usage_count=1,
                last_updated=time.time()
            )
            self.strategies[strategy_name] = new_strategy
            
    def _adjust_learning_parameters(self):
        """è‡ªé€‚åº”è°ƒæ•´å­¦ä¹ å‚æ•°"""
        if len(self.performance_history) >= 10:
            recent_performance = self.performance_history[-10:]
            avg_success_rate = np.mean([p['success_rate'] for p in recent_performance])
            
            # å¦‚æœæ€§èƒ½ä¸‹é™ï¼Œå¢åŠ æ¢ç´¢ç‡
            if avg_success_rate < 0.6:
                self.exploration_rate = min(0.5, self.exploration_rate + 0.05)
            elif avg_success_rate > 0.8:
                self.exploration_rate = max(0.1, self.exploration_rate - 0.02)
                
    def self_evolve(self):
        """è‡ªæˆ‘è¿›åŒ–è¿‡ç¨‹"""
        logger.info("å¼€å§‹è‡ªæˆ‘è¿›åŒ–è¿‡ç¨‹...")
        
        # 1. åˆ†ææœ€è¿‘çš„ç»éªŒæ¨¡å¼
        recent_experiences = self.experiences[-100:] if len(self.experiences) >= 100 else self.experiences
        patterns = self.reflection_module.identify_patterns(recent_experiences)
        
        logger.info(f"è¯†åˆ«åˆ°çš„æ¨¡å¼: {patterns}")
        
        # 2. ç­–ç•¥ä¼˜åŒ–
        self._optimize_strategies()
        
        # 3. çŸ¥è¯†æ•´åˆ
        self._integrate_knowledge()
        
        # 4. èƒ½åŠ›æ‰©å±•
        self._expand_capabilities()
        
        logger.info("è‡ªæˆ‘è¿›åŒ–å®Œæˆ")
        
    def _optimize_strategies(self):
        """ä¼˜åŒ–ç­–ç•¥"""
        # ç§»é™¤ä½æ•ˆç­–ç•¥
        strategies_to_remove = []
        for name, strategy in self.strategies.items():
            if strategy.usage_count > 10 and strategy.success_rate < 0.3:
                strategies_to_remove.append(name)
                
        for name in strategies_to_remove:
            del self.strategies[name]
            logger.info(f"ç§»é™¤ä½æ•ˆç­–ç•¥: {name}")
            
        # åˆå¹¶ç›¸ä¼¼ç­–ç•¥
        self._merge_similar_strategies()
        
    def _merge_similar_strategies(self):
        """åˆå¹¶ç›¸ä¼¼ç­–ç•¥"""
        strategy_list = list(self.strategies.values())
        
        for i, strategy1 in enumerate(strategy_list):
            for j, strategy2 in enumerate(strategy_list[i+1:], i+1):
                if self._strategies_similar(strategy1, strategy2):
                    # åˆå¹¶ç­–ç•¥
                    merged_name = f"åˆå¹¶_{strategy1.name}_{strategy2.name}"
                    merged_strategy = Strategy(
                        name=merged_name,
                        description=f"åˆå¹¶ç­–ç•¥: {strategy1.description} + {strategy2.description}",
                        conditions={**strategy1.conditions, **strategy2.conditions},
                        actions=list(set(strategy1.actions + strategy2.actions)),
                        success_rate=(strategy1.success_rate * strategy1.usage_count + 
                                    strategy2.success_rate * strategy2.usage_count) / 
                                   (strategy1.usage_count + strategy2.usage_count),
                        usage_count=strategy1.usage_count + strategy2.usage_count,
                        last_updated=time.time()
                    )
                    
                    # æ›´æ–°ç­–ç•¥åº“
                    del self.strategies[strategy1.name]
                    del self.strategies[strategy2.name]
                    self.strategies[merged_name] = merged_strategy
                    
                    logger.info(f"åˆå¹¶ç­–ç•¥: {strategy1.name} + {strategy2.name} -> {merged_name}")
                    break
                    
    def _strategies_similar(self, strategy1: Strategy, strategy2: Strategy) -> bool:
        """åˆ¤æ–­ç­–ç•¥æ˜¯å¦ç›¸ä¼¼"""
        # æ£€æŸ¥æ¡ä»¶ç›¸ä¼¼æ€§
        common_conditions = set(strategy1.conditions.keys()) & set(strategy2.conditions.keys())
        if len(common_conditions) / max(len(strategy1.conditions), len(strategy2.conditions)) > 0.5:
            # æ£€æŸ¥åŠ¨ä½œç›¸ä¼¼æ€§
            common_actions = set(strategy1.actions) & set(strategy2.actions)
            if len(common_actions) / max(len(strategy1.actions), len(strategy2.actions)) > 0.5:
                return True
        return False
        
    def _integrate_knowledge(self):
        """æ•´åˆçŸ¥è¯†"""
        # å‘ç°çŸ¥è¯†å›¾è°±ä¸­çš„æ–°å…³è”
        concepts = list(self.knowledge_graph.nodes.keys())
        
        for i, concept1 in enumerate(concepts):
            for concept2 in concepts[i+1:]:
                similarity = self.knowledge_graph.get_concept_similarity(concept1, concept2)
                if similarity > 0.8:  # é«˜ç›¸ä¼¼åº¦é˜ˆå€¼
                    # æ·»åŠ ç›¸ä¼¼æ€§å…³ç³»
                    self.knowledge_graph.add_relation(concept1, concept2, 'similar_to', similarity)
                    
    def _expand_capabilities(self):
        """æ‰©å±•èƒ½åŠ›"""
        # åŸºäºæˆåŠŸç»éªŒå°è¯•å‘ç°æ–°çš„å·¥å…·ç»„åˆ
        successful_experiences = [exp for exp in self.experiences[-50:] if exp.success]
        
        # åˆ†ææˆåŠŸçš„åŠ¨ä½œåºåˆ—
        action_sequences = []
        for i in range(len(successful_experiences) - 1):
            if successful_experiences[i].timestamp < successful_experiences[i+1].timestamp:
                sequence = (successful_experiences[i].action, successful_experiences[i+1].action)
                action_sequences.append(sequence)
        
        # å‘ç°å¸¸è§çš„æˆåŠŸåºåˆ—
        sequence_counts = {}
        for seq in action_sequences:
            sequence_counts[seq] = sequence_counts.get(seq, 0) + 1
            
        # åˆ›å»ºæ–°çš„ç»„åˆå·¥å…·
        for sequence, count in sequence_counts.items():
            if count >= 3:  # å‡ºç°3æ¬¡ä»¥ä¸Šçš„åºåˆ—
                combo_name = f"combo_{sequence[0]}_{sequence[1]}"
                if combo_name not in self.available_tools:
                    self.available_tools[combo_name] = self._create_combo_tool(sequence)
                    logger.info(f"å‘ç°æ–°çš„å·¥å…·ç»„åˆ: {combo_name}")
                    
    def _create_combo_tool(self, sequence: Tuple[str, str]) -> Callable:
        """åˆ›å»ºç»„åˆå·¥å…·"""
        def combo_tool(context):
            # ä¾æ¬¡æ‰§è¡Œåºåˆ—ä¸­çš„å·¥å…·
            result1 = self.available_tools[sequence[0]](context)
            # å°†ç¬¬ä¸€ä¸ªå·¥å…·çš„ç»“æœä½œä¸ºç¬¬äºŒä¸ªå·¥å…·çš„è¾“å…¥
            enhanced_context = {**context, 'previous_result': result1}
            result2 = self.available_tools[sequence[1]](enhanced_context)
            
            return {
                'sequence_results': [result1, result2],
                'final_result': result2,
                'combo_success': True
            }
        return combo_tool
        
    def process_task(self, task: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """å¤„ç†ä»»åŠ¡çš„ä¸»è¦æ¥å£"""
        if context is None:
            context = {'task': task}
        else:
            context['task'] = task
            
        logger.info(f"å¤„ç†ä»»åŠ¡: {task}")
        
        # 1. ç¯å¢ƒæ„ŸçŸ¥
        perception = self.perceive_environment(context)
        
        # 2. å†³ç­–è¡ŒåŠ¨
        action = self.decide_action(perception)
        
        # 3. æ‰§è¡ŒåŠ¨ä½œ
        result = self.execute_action(action, context)
        
        # 4. è¯„ä¼°ç»“æœ
        success, reward = self.evaluate_result(result)
        
        # 5. åˆ›å»ºç»éªŒ
        experience = Experience(
            task=task,
            context=context,
            action=action,
            result=result,
            success=success,
            reward=reward,
            timestamp=time.time()
        )
        
        # 6. å­¦ä¹ 
        self.learn_from_experience(experience)
        
        # 7. å®šæœŸè‡ªæˆ‘è¿›åŒ–
        if len(self.experiences) % 50 == 0:  # æ¯50ä¸ªç»éªŒè¿›åŒ–ä¸€æ¬¡
            self.self_evolve()
            
        return {
            'task': task,
            'action': action,
            'result': result,
            'success': success,
            'reward': reward,
            'learning_insights': experience.reflection
        }
        
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        if not self.performance_history:
            return {'message': 'æš‚æ— æ€§èƒ½æ•°æ®'}
            
        latest_performance = self.performance_history[-1]
        
        # è®¡ç®—è¶‹åŠ¿
        if len(self.performance_history) >= 10:
            recent_avg = np.mean([p['success_rate'] for p in self.performance_history[-10:]])
            overall_avg = np.mean([p['success_rate'] for p in self.performance_history])
            trend = 'improving' if recent_avg > overall_avg else 'declining'
        else:
            trend = 'insufficient_data'
            
        return {
            'total_tasks': self.total_tasks,
            'successful_tasks': self.successful_tasks,
            'current_success_rate': latest_performance['success_rate'],
            'trend': trend,
            'strategies_count': len(self.strategies),
            'experiences_count': len(self.experiences),
            'exploration_rate': self.exploration_rate,
            'knowledge_concepts': len(self.knowledge_graph.nodes)
        }
        
    def save_state(self, filepath: str):
        """ä¿å­˜AgentçŠ¶æ€"""
        state = {
            'name': self.name,
            'experiences': [exp.to_dict() for exp in self.experiences],
            'strategies': {name: strategy.to_dict() for name, strategy in self.strategies.items()},
            'performance_history': self.performance_history,
            'total_tasks': self.total_tasks,
            'successful_tasks': self.successful_tasks,
            'learning_rate': self.learning_rate,
            'exploration_rate': self.exploration_rate,
            'knowledge_graph_nodes': self.knowledge_graph.nodes,
            'knowledge_graph_edges': self.knowledge_graph.edges,
            'timestamp': time.time()
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
            
        logger.info(f"AgentçŠ¶æ€å·²ä¿å­˜åˆ°: {filepath}")
        
    def load_state(self, filepath: str):
        """åŠ è½½AgentçŠ¶æ€"""
        with open(filepath, 'r', encoding='utf-8') as f:
            state = json.load(f)
            
        self.name = state['name']
        self.total_tasks = state['total_tasks']
        self.successful_tasks = state['successful_tasks']
        self.learning_rate = state['learning_rate']
        self.exploration_rate = state['exploration_rate']
        self.performance_history = state['performance_history']
        
        # é‡å»ºç»éªŒ
        self.experiences = []
        for exp_dict in state['experiences']:
            exp = Experience(**exp_dict)
            self.experiences.append(exp)
            
        # é‡å»ºç­–ç•¥
        self.strategies = {}
        for name, strategy_dict in state['strategies'].items():
            strategy = Strategy(**strategy_dict)
            self.strategies[name] = strategy
            
        # é‡å»ºçŸ¥è¯†å›¾è°±
        self.knowledge_graph.nodes = state['knowledge_graph_nodes']
        self.knowledge_graph.edges = state['knowledge_graph_edges']
        
        logger.info(f"AgentçŠ¶æ€å·²ä» {filepath} åŠ è½½")


def demo_self_evolving_agent():
    """æ¼”ç¤ºè‡ªè¿›åŒ–Agent"""
    print("=== è‡ªè¿›åŒ–è‡ªå­¦ä¹ Agentæ¼”ç¤º ===")
    
    # åˆ›å»ºAgent
    agent = SelfEvolvingAgent("å­¦ä¹ å‹AIåŠ©æ‰‹")
    
    # æ¨¡æ‹Ÿä»»åŠ¡åºåˆ—
    tasks = [
        ("æœç´¢Pythonæ•™ç¨‹", {'query': 'PythonåŸºç¡€æ•™ç¨‹', 'difficulty': 'beginner'}),
        ("è®¡ç®—å¤åˆåˆ©ç‡", {'expression': '1000 * (1.05 ** 10)', 'context': 'finance'}),
        ("åˆ†æç”¨æˆ·æ•°æ®", {'data': {'users': 100, 'active': 80, 'retention': 0.75}}),
        ("åˆ¶å®šå­¦ä¹ è®¡åˆ’", {'goal': 'æŒæ¡æœºå™¨å­¦ä¹ ', 'timeframe': '3ä¸ªæœˆ'}),
        ("æœç´¢æœºå™¨å­¦ä¹ èµ„æº", {'query': 'æœºå™¨å­¦ä¹ å…¥é—¨', 'difficulty': 'intermediate'}),
        ("åˆ†æå­¦ä¹ è¿›åº¦", {'data': {'completed': 5, 'total': 20, 'avg_score': 85}}),
        ("è®¡ç®—å­¦ä¹ æ•ˆç‡", {'expression': '85 / 100 * 0.8', 'context': 'learning'}),
        ("ä¼˜åŒ–å­¦ä¹ ç­–ç•¥", {'goal': 'æé«˜å­¦ä¹ æ•ˆç‡', 'current_rate': 0.68})
    ]
    
    print(f"\nå‡†å¤‡å¤„ç† {len(tasks)} ä¸ªä»»åŠ¡...\n")
    
    # å¤„ç†ä»»åŠ¡å¹¶è§‚å¯Ÿå­¦ä¹ è¿‡ç¨‹
    for i, (task, context) in enumerate(tasks, 1):
        print(f"--- ä»»åŠ¡ {i}: {task} ---")
        
        result = agent.process_task(task, context)
        
        print(f"é€‰æ‹©çš„è¡ŒåŠ¨: {result['action']}")
        print(f"æ‰§è¡Œç»“æœ: {result['success']}")
        print(f"å¥–åŠ±å€¼: {result['reward']:.2f}")
        print(f"å­¦ä¹ æ´å¯Ÿ: {result['learning_insights']}")
        
        # æ˜¾ç¤ºå½“å‰æ€§èƒ½
        if i % 3 == 0:  # æ¯3ä¸ªä»»åŠ¡æ˜¾ç¤ºä¸€æ¬¡æ€§èƒ½æ‘˜è¦
            performance = agent.get_performance_summary()
            print(f"\nğŸ“Š å½“å‰æ€§èƒ½æ‘˜è¦:")
            print(f"  æ€»ä»»åŠ¡æ•°: {performance['total_tasks']}")
            print(f"  æˆåŠŸç‡: {performance['current_success_rate']:.2%}")
            print(f"  ç­–ç•¥æ•°é‡: {performance['strategies_count']}")
            print(f"  çŸ¥è¯†æ¦‚å¿µ: {performance['knowledge_concepts']}")
            print(f"  æ¢ç´¢ç‡: {performance['exploration_rate']:.2f}")
            
        print()
        
    # æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š
    print("\n=== æœ€ç»ˆå­¦ä¹ æŠ¥å‘Š ===")
    final_performance = agent.get_performance_summary()
    
    print(f"æ€»å¤„ç†ä»»åŠ¡: {final_performance['total_tasks']}")
    print(f"æœ€ç»ˆæˆåŠŸç‡: {final_performance['current_success_rate']:.2%}")
    print(f"æ€§èƒ½è¶‹åŠ¿: {final_performance['trend']}")
    print(f"å­¦ä¹ ç­–ç•¥æ•°: {final_performance['strategies_count']}")
    print(f"çŸ¥è¯†æ¦‚å¿µæ•°: {final_performance['knowledge_concepts']}")
    
    # æ˜¾ç¤ºå­¦åˆ°çš„ç­–ç•¥
    print("\nğŸ§  å­¦åˆ°çš„ç­–ç•¥:")
    for name, strategy in agent.strategies.items():
        if strategy.usage_count > 0:
            print(f"  {name}: æˆåŠŸç‡ {strategy.success_rate:.2%}, ä½¿ç”¨ {strategy.usage_count} æ¬¡")
            
    # ä¿å­˜AgentçŠ¶æ€
    agent.save_state("agent_state.json")
    print("\nğŸ’¾ AgentçŠ¶æ€å·²ä¿å­˜åˆ° agent_state.json")
    
    return agent


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    agent = demo_self_evolving_agent()